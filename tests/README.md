# CandidateFilings Pipeline Tests

This directory contains comprehensive tests for the CandidateFilings.com data processing pipeline.

## ğŸ§ª **Test Coverage**

### **Core Pipeline Tests** (`test_main_pipeline.py`)
- âœ… Pipeline initialization and configuration
- âœ… Raw data file discovery and processing
- âœ… State file merging and validation
- âœ… Office standardization integration
- âœ… State cleaner mapping validation
- âœ… Pipeline status tracking
- âœ… Error handling in file operations
- âœ… Cleanup operations

### **Office Standardizer Tests** (`test_office_standardizer.py`)
- âœ… Standardizer initialization and configuration
- âœ… Office name categorization
- âœ… Confidence scoring
- âœ… Partial matching algorithms
- âœ… Edge case handling
- âœ… Dataset standardization
- âœ… Category mapping validation

### **Error Handling Tests** (`test_error_handling.py`)
- âœ… Graceful degradation on component failures
- âœ… Empty DataFrame handling
- âœ… Missing column handling
- âœ… File I/O error handling
- âœ… Database connection failure handling
- âœ… Office standardization failure handling
- âœ… Audit failure handling
- âœ… Progress tracking validation
- âœ… Error logging capabilities

### **Database Tests** (`test_database.py`)
- âœ… Database manager initialization
- âœ… Connection success/failure handling
- âœ… Query execution
- âœ… DataFrame uploads
- âœ… Table operations
- âœ… Environment variable validation
- âœ… Chunked upload for large datasets
- âœ… Connection string formatting

## ğŸš€ **Running Tests**

### **Install Testing Dependencies**
```bash
pip install -r requirements.txt
```

### **Run All Tests**
```bash
# From project root
python -m pytest tests/ -v

# Or use the test runner
python tests/run_tests.py
```

### **Run Specific Test Files**
```bash
# Run main pipeline tests only
python tests/run_tests.py test_main_pipeline.py

# Run error handling tests only
python tests/run_tests.py test_error_handling.py

# Run office standardizer tests only
python tests/run_tests.py test_office_standardizer.py

# Run database tests only
python tests/run_tests.py test_database.py
```

### **Run with Coverage**
```bash
python -m pytest tests/ --cov=src --cov-report=html
```

## ğŸ“‹ **Test Categories**

### **Unit Tests**
- Individual component functionality
- Method behavior validation
- Input/output validation
- Edge case handling

### **Integration Tests**
- Component interaction testing
- Data flow validation
- Pipeline stage coordination
- Error propagation testing

### **Error Handling Tests**
- Failure scenario testing
- Graceful degradation validation
- Error logging verification
- Recovery mechanism testing

### **Data Validation Tests**
- Schema compliance checking
- Data quality validation
- File format handling
- Column validation

## ğŸ”§ **Test Configuration**

### **Fixtures** (`conftest.py`)
- `sample_candidate_data`: Sample candidate data for testing
- `temp_data_dir`: Temporary directory for test files
- `mock_database`: Mock database connection
- `sample_state_files`: Sample state data files

### **Mocking Strategy**
- Database connections mocked for unit testing
- File I/O operations use temporary directories
- State cleaners mocked for failure testing
- Environment variables mocked for database tests

## ğŸ“Š **Test Results**

### **Expected Output**
```
ğŸ§ª Running CandidateFilings Pipeline Tests...
==================================================
test_main_pipeline.py::TestMainPipeline::test_pipeline_initialization PASSED
test_main_pipeline.py::TestMainPipeline::test_pipeline_creates_directories PASSED
...
ğŸ‰ All tests passed!
```

### **Test Statistics**
- **Total Tests**: 40+ test methods
- **Coverage Areas**: Core pipeline, office standardizer, error handling, database
- **Test Types**: Unit, integration, error handling, validation
- **Mock Usage**: Database, file I/O, external dependencies

## ğŸš¨ **Troubleshooting**

### **Common Test Issues**
1. **Import Errors**: Ensure you're running from project root
2. **Missing Dependencies**: Install with `pip install -r requirements.txt`
3. **File Permission Issues**: Check write access to temp directories
4. **Mock Configuration**: Verify mock setup in test files

### **Test Debugging**
```bash
# Run with detailed output
python -m pytest tests/ -v -s

# Run single test method
python -m pytest tests/test_main_pipeline.py::TestMainPipeline::test_pipeline_initialization -v

# Run with print statements
python -m pytest tests/ -s
```

## ğŸ¯ **Adding New Tests**

### **Test File Structure**
```python
"""
Tests for [component name].
"""

import pytest
from [component_path] import [ComponentClass]

class Test[ComponentName]:
    """Test the [component name] component."""
    
    def test_[specific_functionality](self):
        """Test [specific functionality description]."""
        # Test implementation
        assert True
```

### **Test Naming Convention**
- Test classes: `Test[ComponentName]`
- Test methods: `test_[functionality_description]`
- Use descriptive names that explain what is being tested

### **Test Organization**
- Group related tests in the same class
- Use fixtures for common test data
- Mock external dependencies
- Test both success and failure scenarios

## ğŸ“ˆ **Continuous Integration**

### **GitHub Actions** (Recommended)
```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: python -m pytest tests/ -v
```

### **Pre-commit Hooks**
```bash
# Install pre-commit
pip install pre-commit

# Run tests before commit
pre-commit install
```

## ğŸ† **Test Quality Standards**

### **Coverage Requirements**
- **Minimum Coverage**: 80%
- **Critical Paths**: 100% coverage
- **Error Handling**: 90% coverage
- **Integration Points**: 95% coverage

### **Test Quality Checklist**
- [ ] Tests are descriptive and readable
- [ ] Edge cases are covered
- [ ] Error scenarios are tested
- [ ] Mocks are properly configured
- [ ] Test data is realistic
- [ ] Assertions are specific
- [ ] Tests are independent
- [ ] Cleanup is handled properly

## ğŸ“š **Additional Resources**

- **Pytest Documentation**: https://docs.pytest.org/
- **Mock Documentation**: https://docs.python.org/3/library/unittest.mock.html
- **Testing Best Practices**: https://realpython.com/python-testing/
- **Pipeline Testing Patterns**: https://martinfowler.com/articles/microservice-testing/
